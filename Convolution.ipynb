{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------with_scratch-------------------------\n",
      " tensor([[[-0.3670,  0.5096, -0.4808,  0.1001],\n",
      "         [ 0.4391,  0.5202,  0.4944,  0.3177],\n",
      "         [ 0.6329,  0.1589, -1.3393, -0.0122],\n",
      "         [-0.2328,  0.2560,  1.1390, -0.0174]],\n",
      "\n",
      "        [[-0.0180,  0.5075, -0.2094, -0.1865],\n",
      "         [ 0.0300, -0.4103, -0.0334, -0.1297],\n",
      "         [ 0.3028, -0.0608,  0.0752,  1.0516],\n",
      "         [-0.1494, -0.1147, -0.0413, -1.0659]]], grad_fn=<CopySlices>)\n",
      "\n",
      "-------------------------------with_module--------------------------\n",
      " tensor([[[-0.3670,  0.5096, -0.4808,  0.1001],\n",
      "         [ 0.4391,  0.5202,  0.4944,  0.3177],\n",
      "         [ 0.6329,  0.1589, -1.3393, -0.0122],\n",
      "         [-0.2328,  0.2560,  1.1390, -0.0174]],\n",
      "\n",
      "        [[-0.0180,  0.5075, -0.2094, -0.1865],\n",
      "         [ 0.0300, -0.4103, -0.0334, -0.1297],\n",
      "         [ 0.3028, -0.0608,  0.0752,  1.0516],\n",
      "         [-0.1494, -0.1147, -0.0413, -1.0659]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "\n",
      "----------------------------------valid-----------------------------\n",
      " tensor([[[True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True],\n",
      "         [True, True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "cin = 3 # input channel size\n",
    "cout = 4 # output channel size\n",
    "k_size = 2 # kernel size\n",
    "stride = 1\n",
    "padding = 1\n",
    "dilation = 2\n",
    "\n",
    "# create_data\n",
    "torch.manual_seed(42)\n",
    "n = 2\n",
    "lin = 4\n",
    "x = torch.randn(n,cin,lin)\n",
    "\n",
    "# convolution with module\n",
    "conv = nn.Conv1d(cin, cout ,k_size, stride, padding, dilation=dilation)\n",
    "linear = nn.Linear(5,3)\n",
    "mout = conv(x)\n",
    "\n",
    "# --------------- scratch  --------------\n",
    "# padding\n",
    "x_padded = F.pad(x, (padding, padding), 'constant', 0)\n",
    "# convolution with scratch\n",
    "lout = (lin + 2*padding - dilation*(k_size-1) - 1)//stride + 1\n",
    "sout = torch.zeros(n, cout, lout)\n",
    "for i in range(n):\n",
    "    for j in range(cout):\n",
    "        for l in range(lout):\n",
    "            trg = x_padded[i, :, l:l + k_size + dilation - 1:dilation]\n",
    "            sout[i,j,l] = torch.sum(trg*conv.weight[j]) + conv.bias[j]\n",
    "\n",
    "print('-------------------------------with_scratch-------------------------\\n', sout)\n",
    "print()\n",
    "print('-------------------------------with_module--------------------------\\n', mout)\n",
    "print()\n",
    "print('----------------------------------valid-----------------------------\\n',\n",
    "torch.round(mout, decimals=5)==torch.round(sout, decimals=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d():\n",
    "    def __init__(self, cin: int, cout: int, k_size: int,\n",
    "                    stride: int, padding: int, dilation: int):\n",
    "        \"\"\"\n",
    "        cin : input_channel_size_\n",
    "        cout : output_channel_size_\n",
    "        k_size : kernel_size_\n",
    "        \"\"\"\n",
    "        self.cin = cin\n",
    "        self.cout = cout\n",
    "        self.k_size = k_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        \n",
    "        self.weight = np.random.randn(cout, cin, k_size)\n",
    "        self.bias = np.random.randn(cout)\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray: \n",
    "        \"\"\" forward_propagation\n",
    "        x : input_data_ (batch_size, cin, lin)\n",
    "        out : output_data_ (batch_size, cout, lout)\n",
    "        \"\"\"\n",
    "        # padding\n",
    "        x_padded = np.pad(x, [(0,0),(0,0),(self.padding, self.padding)], 'constant')\n",
    "        self.x_padded = x_padded\n",
    "        # convolution\n",
    "        lout = (lin + 2*padding - dilation*(self.k_size-1) - 1)//stride + 1\n",
    "        output = torch.zeros(n, cout, lout)\n",
    "        for i in range(n):\n",
    "            for j in range(cout):\n",
    "                for l in range(lout):\n",
    "                    trg = x_padded[i, :, l:l + self.k_size + dilation - 1:dilation]\n",
    "                    output[i,j,l] = torch.sum(trg*conv.weight[j]) + conv.bias[j]\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad: np.ndarray) -> np.ndarray:\n",
    "        grad = self.x_padded * grad\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  1.926915  ,  1.4872842 ,\n",
       "          0.9007172 , -2.1055214 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.67841846, -1.234545  ,\n",
       "         -0.04306748, -1.604667  ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.3558598 , -0.686623  ,\n",
       "         -0.49335635,  0.2414878 ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -1.1109041 ,  0.09154566,\n",
       "         -2.3169227 , -0.21680473,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.30972692, -0.3957105 ,\n",
       "          0.80340934, -0.6215954 ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.5920003 , -0.06307438,\n",
       "         -0.8285543 ,  0.33089843,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(x, [(0,0),(0,0),(2,1)], 'constant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
